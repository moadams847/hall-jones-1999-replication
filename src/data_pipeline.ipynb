{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59f4b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "\n",
    "\"\"\"\n",
    "Hall & Jones (1999) Replication — Data Merge Pipeline\n",
    "======================================================\n",
    "Merges all datasets step by step, with checks at each stage.\n",
    "\n",
    "Run this script from the folder where your data files are located,\n",
    "or update the file paths in the CONFIG section below.\n",
    "\n",
    "Steps:\n",
    "  1. PWT 10.01        → output per worker, investment share, employment (1988)\n",
    "  2. Capital stock    → constructed via perpetual inventory method within PWT\n",
    "  3. Barro-Lee 2013   → average years of schooling (1985)\n",
    "  4. Human capital    → computed from Barro-Lee using piecewise Mincerian returns\n",
    "  5. Mining VA        → mining value added as % of GDP (1990 proxy for 1988)\n",
    "  6. WGI governance   → composite index from rl, ge, cc (substitute for GADP)\n",
    "  7. Sachs-Warner     → openness fraction (fraction of years open 1950-1992)\n",
    "  8. Instruments      → distance from equator, FR trade, language fractions\n",
    "\n",
    "Output: hj_master.csv — one row per country, ready for analysis\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIG — update these paths if needed\n",
    "# =============================================================================\n",
    "PWT_FILE        = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\GDP, Investment, and Labor force\\\\pwt1001.xlsx\"\n",
    "\n",
    "BL_FILE         = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\Barro-Lee dataset\\\\BL2013_MF2599_v2.csv\"\n",
    "\n",
    "MINING_FILE     = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\MINING VALUE ADDED\\\\Contribution of mining to value added.xlsx\"\n",
    "\n",
    "WGI_FILE        = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\For Index\\\\World Bank Governance Indicators\\\\wgidataset_with_sourcedata-2025.xlsx\"\n",
    "\n",
    "OPEN_FILE       = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\For Index\\\\SACHS-WARNER OPENNESS INDEX\\\\open.csv\"\n",
    "\n",
    "GEO_FILE        = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\INSTRUMENTAL Variables Data\\\\geo_instruments.csv\"\n",
    "FR_FILE         = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\INSTRUMENTAL Variables Data\\\\frankel_romer_trade.csv\"\n",
    "LANG_FILE       = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\Data\\\\INSTRUMENTAL Variables Data\\\\language_instruments.csv\"\n",
    "\n",
    "OUTPUT_FILE     = \"C:\\\\Users\\\\Adams\\\\OneDrive\\\\DE & E Research\\\\outputs\\\\merged.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58299085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def read_xlsx_sheet(filepath, sheet_index=0):\n",
    "    \"\"\"\n",
    "    Read a sheet from an xlsx file.\n",
    "    Returns (headers, rows) where rows is a list of dicts.\n",
    "    sheet_index: 0-based index of the sheet to read.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(filepath, 'r') as z:\n",
    "        # Read shared strings\n",
    "        with z.open('xl/sharedStrings.xml') as f:\n",
    "            tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "            ns = {'ns': 'http://schemas.openxmlformats.org/spreadsheetml/2006/main'}\n",
    "            strings = []\n",
    "            for si in root.findall('ns:si', ns):\n",
    "                t = si.find('ns:t', ns)\n",
    "                if t is not None:\n",
    "                    strings.append(t.text or '')\n",
    "                else:\n",
    "                    texts = si.findall('.//ns:t', ns)\n",
    "                    strings.append(''.join(t.text or '' for t in texts))\n",
    "\n",
    "        # Find sheet files in order\n",
    "        sheet_files = sorted([\n",
    "            n for n in z.namelist()\n",
    "            if 'worksheets/sheet' in n and n.endswith('.xml')\n",
    "        ])\n",
    "\n",
    "        def get_val(cell, strings):\n",
    "            t = cell.get('t')\n",
    "            v = cell.find('{http://schemas.openxmlformats.org/spreadsheetml/2006/main}v')\n",
    "            if v is None:\n",
    "                return None\n",
    "            if t == 's':\n",
    "                idx = int(v.text)\n",
    "                return strings[idx] if idx < len(strings) else None\n",
    "            return v.text\n",
    "\n",
    "        with z.open(sheet_files[sheet_index]) as f:\n",
    "            tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "            rows = root.findall(\n",
    "                './/{http://schemas.openxmlformats.org/spreadsheetml/2006/main}row'\n",
    "            )\n",
    "\n",
    "        if not rows:\n",
    "            return [], []\n",
    "\n",
    "        headers = [get_val(c, strings) for c in rows[0]]\n",
    "        data = []\n",
    "        for row in rows[1:]:\n",
    "            vals = [get_val(c, strings) for c in row]\n",
    "            d = dict(zip(headers, vals))\n",
    "            data.append(d)\n",
    "\n",
    "        return headers, data\n",
    "\n",
    "\n",
    "def safe_float(val, default=None):\n",
    "    \"\"\"Convert a value to float, returning default if conversion fails.\"\"\"\n",
    "    if val is None or val == '':\n",
    "        return default\n",
    "    try:\n",
    "        return float(val)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def safe_print(label, df):\n",
    "    \"\"\"Print a summary of the current dataset.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {label}\")\n",
    "    print(f\"  Countries: {len(df)}\")\n",
    "    cols = list(df[list(df.keys())[0]].keys()) if df else []\n",
    "    print(f\"  Variables: {cols}\")\n",
    "    # Count missing values for key variables\n",
    "    for key_var in ['yl', 'hc', 'csh_i', 'yr_sch', 'mining_va', 'governance', 'openness']:\n",
    "        if df and key_var in list(df.values())[0]:\n",
    "            n_missing = sum(1 for v in df.values() if v.get(key_var) is None)\n",
    "            print(f\"  Missing {key_var}: {n_missing}\")\n",
    "    print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0cfed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 1: Loading PWT 10.01...\n",
      "  PWT total rows loaded: 12810\n",
      "  Countries in 1988: 183\n",
      "  Countries with Y/L: 149\n",
      "  USA Y/L check: 79440 (2017 USD PPP)\n",
      "  Niger Y/L check: 2987 (2017 USD PPP)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: PWT 10.01 — Extract 1988 data\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 1: Loading PWT 10.01...\")\n",
    "\n",
    "# PWT has 3 sheets: Info (index 0), Legend (index 1), Data (index 2)\n",
    "# Based on our earlier inspection: sheet file order is sheet1=Info, sheet2=Legend, sheet3=Data\n",
    "# But the workbook maps: Data=sheet id 1, Info=sheet id 2, Legend=sheet id 3\n",
    "# The sheet files are sorted: sheet1.xml, sheet2.xml, sheet3.xml\n",
    "# From our earlier inspection sheet3.xml = Data\n",
    "_, pwt_rows = read_xlsx_sheet(PWT_FILE, sheet_index=2)\n",
    "\n",
    "print(f\"  PWT total rows loaded: {len(pwt_rows)}\")\n",
    "\n",
    "# Filter to year 1988\n",
    "pwt_1988 = {}\n",
    "for row in pwt_rows:\n",
    "    if row.get('year') == '1988':\n",
    "        iso = row.get('countrycode', '').strip()\n",
    "        if not iso:\n",
    "            continue\n",
    "\n",
    "        rgdpo  = safe_float(row.get('rgdpo'))   # Output-side real GDP (mil 2017 USD PPP)\n",
    "        emp    = safe_float(row.get('emp'))      # Employment (millions)\n",
    "        pop    = safe_float(row.get('pop'))      # Population (millions)\n",
    "        csh_i  = safe_float(row.get('csh_i'))    # Investment share of GDP\n",
    "        hc_pwt = safe_float(row.get('hc'))       # PWT human capital index (backup)\n",
    "        delta  = safe_float(row.get('delta'))    # Depreciation rate\n",
    "        rkna   = safe_float(row.get('rkna'))     # Capital stock (nat. accounts, mil 2017 USD)\n",
    "        labsh  = safe_float(row.get('labsh'))    # Labor share\n",
    "\n",
    "        # Output per worker: Y/L\n",
    "        yl = (rgdpo / emp) if (rgdpo and emp and emp > 0) else None\n",
    "\n",
    "        pwt_1988[iso] = {\n",
    "            'country':  row.get('country', ''),\n",
    "            'iso3':     iso,\n",
    "            'rgdpo':    rgdpo,\n",
    "            'emp':      emp,\n",
    "            'pop':      pop,\n",
    "            'csh_i':    csh_i,\n",
    "            'hc_pwt':   hc_pwt,\n",
    "            'delta':    delta,\n",
    "            'rkna':     rkna,\n",
    "            'labsh':    labsh,\n",
    "            'yl':       yl,        # Output per worker (main dependent variable)\n",
    "        }\n",
    "\n",
    "print(f\"  Countries in 1988: {len(pwt_1988)}\")\n",
    "print(f\"  Countries with Y/L: {sum(1 for v in pwt_1988.values() if v['yl'] is not None)}\")\n",
    "\n",
    "# Quick sanity check: US output per worker should be high\n",
    "if 'USA' in pwt_1988:\n",
    "    print(f\"  USA Y/L check: {pwt_1988['USA']['yl']:.0f} (2017 USD PPP)\")\n",
    "if 'NER' in pwt_1988:\n",
    "    print(f\"  Niger Y/L check: {pwt_1988['NER']['yl']:.0f} (2017 USD PPP)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd74e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 2: Constructing capital stocks via perpetual inventory...\n",
      "  Loading all PWT years for capital stock construction...\n",
      "  Capital stocks constructed for: 183 countries\n",
      "  USA K/Y ratio: 2.839\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: Capital Stock — Perpetual Inventory Method\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 2: Constructing capital stocks via perpetual inventory...\")\n",
    "\n",
    "# Formula: K_t = I_t + (1 - delta) * K_{t-1}\n",
    "# Initial value: K_0 = I_0 / (g + delta)\n",
    "#   where g = average geometric growth rate of investment over first 10 years\n",
    "# We use delta = 0.06 (Hall & Jones assumption)\n",
    "\n",
    "#rgdpo = Output-side real GDP at chained PPPs (in mil. 2017US$) \n",
    "#csh_i = Investment share of GDP (unitless, e.g. 0.20 for 20%)\n",
    "# Investment I_t = csh_i * rgdpo (investment in mil 2017 USD)\n",
    "\n",
    "DELTA = 0.06  # depreciation rate\n",
    "\n",
    "# Load all PWT years for capital stock construction\n",
    "print(\"  Loading all PWT years for capital stock construction...\")\n",
    "all_pwt = defaultdict(dict)\n",
    "for row in pwt_rows:\n",
    "    iso = row.get('countrycode', '').strip()\n",
    "    yr  = row.get('year', '').strip()\n",
    "    if not iso or not yr:\n",
    "        continue\n",
    "    try:\n",
    "        year = int(float(yr))\n",
    "    except:\n",
    "        continue\n",
    "    rgdpo = safe_float(row.get('rgdpo'))\n",
    "    csh_i = safe_float(row.get('csh_i'))\n",
    "    # Investment = investment share * GDP\n",
    "    inv = rgdpo * csh_i if (rgdpo and csh_i) else None\n",
    "    all_pwt[iso][year] = inv\n",
    "\n",
    "capital_stocks = {}\n",
    "for iso, inv_series in all_pwt.items():\n",
    "    years_with_data = sorted(y for y, v in inv_series.items() if v is not None)\n",
    "    if not years_with_data:\n",
    "        continue\n",
    "\n",
    "    # Only proceed if we have data up to 1988\n",
    "    if 1988 not in years_with_data and max(years_with_data) < 1988:\n",
    "        continue\n",
    "\n",
    "    first_year = years_with_data[0]\n",
    "\n",
    "    # Compute initial growth rate from first 10 years of data\n",
    "    early_years = [y for y in years_with_data if y <= first_year + 10]\n",
    "    if len(early_years) >= 2:\n",
    "        i_start = inv_series[early_years[0]]\n",
    "        i_end   = inv_series[early_years[-1]]\n",
    "        n_yrs   = early_years[-1] - early_years[0]\n",
    "        if i_start and i_end and i_start > 0 and i_end > 0 and n_yrs > 0:\n",
    "            g = (i_end / i_start) ** (1 / n_yrs) - 1\n",
    "        else:\n",
    "            g = 0.02  # default growth rate if data is problematic\n",
    "    else:\n",
    "        g = 0.02\n",
    "\n",
    "    # Initial capital stock\n",
    "    i0 = inv_series.get(first_year)\n",
    "    if i0 is None or i0 <= 0:\n",
    "        continue\n",
    "    k = i0 / (g + DELTA)\n",
    "\n",
    "    # Iterate forward to 1988\n",
    "    for year in range(first_year + 1, 1989):\n",
    "        inv = inv_series.get(year)\n",
    "        if inv is not None and inv >= 0:\n",
    "            k = inv + (1 - DELTA) * k\n",
    "        else:\n",
    "            # Missing year: just depreciate\n",
    "            k = (1 - DELTA) * k\n",
    "\n",
    "    capital_stocks[iso] = k\n",
    "\n",
    "# Merge capital stock into master\n",
    "for iso in pwt_1988:\n",
    "    k = capital_stocks.get(iso)\n",
    "    pwt_1988[iso]['K'] = k\n",
    "    # Capital-output ratio K/Y (key input for production function)\n",
    "    ky = (k / pwt_1988[iso]['rgdpo']) if (k and pwt_1988[iso].get('rgdpo')) else None\n",
    "    pwt_1988[iso]['ky_ratio'] = ky\n",
    "\n",
    "print(f\"  Capital stocks constructed for: {sum(1 for v in pwt_1988.values() if v.get('K') is not None)} countries\")\n",
    "print(f\"  USA K/Y ratio: {pwt_1988.get('USA', {}).get('ky_ratio', 'NA'):.3f}\" if pwt_1988.get('USA', {}).get('ky_ratio') else \"  USA K/Y: NA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3a1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 3: Loading Barro-Lee education data (1985)...\n",
      "  Countries with 1985 education data: 146\n",
      "\n",
      ">>> STEP 4: Computing human capital index from Barro-Lee...\n",
      "  Human capital index computed for: 146 countries\n",
      "  USA h check:   3.3923\n",
      "  Niger h check: 1.0765\n",
      "  Matched Barro-Lee to PWT: 138 countries\n",
      "  Using PWT hc as fallback for: 5 countries\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: Barro-Lee Education Data (1985)\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 3: Loading Barro-Lee education data (1985)...\")\n",
    "\n",
    "bl_data = {}\n",
    "with open(BL_FILE, 'r', encoding='latin1') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Use year=1985, sex=MF, age 25+\n",
    "        if row.get('year') == '1985' and row.get('sex') == 'MF' and row.get('agefrom') == '25':\n",
    "            iso = row.get('WBcode', '').strip()\n",
    "            yr_sch = safe_float(row.get('yr_sch'))\n",
    "            if iso:\n",
    "                bl_data[iso] = {'yr_sch': yr_sch}\n",
    "\n",
    "print(f\"  Countries with 1985 education data: {len(bl_data)}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: Human Capital Index (Piecewise Mincerian Returns)\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 4: Computing human capital index from Barro-Lee...\")\n",
    "\n",
    "# Hall & Jones use piecewise Mincerian returns (Psacharopoulos 1994):\n",
    "#   Years 1-4:  13.4% return per year (sub-Saharan Africa average)\n",
    "#   Years 5-8:  10.1% return per year (world average)\n",
    "#   Years 9+:    6.8% return per year (OECD average)\n",
    "#\n",
    "# Human capital index: h = exp(phi(E))\n",
    "# phi(E) = 0.134*min(E,4) + 0.101*max(min(E,8)-4,0) + 0.068*max(E-8,0)\n",
    "\n",
    "def mincerian_phi(E):\n",
    "    \"\"\"Compute piecewise Mincerian returns for E years of schooling.\"\"\"\n",
    "    if E is None:\n",
    "        return None\n",
    "    e1 = min(E, 4)\n",
    "    e2 = max(min(E, 8) - 4, 0)\n",
    "    e3 = max(E - 8, 0)\n",
    "    return 0.134 * e1 + 0.101 * e2 + 0.068 * e3\n",
    "\n",
    "for iso, d in bl_data.items():\n",
    "    phi = mincerian_phi(d.get('yr_sch'))\n",
    "    d['hc_bl'] = math.exp(phi) if phi is not None else None\n",
    "\n",
    "print(f\"  Human capital index computed for: {sum(1 for d in bl_data.values() if d.get('hc_bl') is not None)} countries\")\n",
    "print(f\"  USA h check:   {bl_data.get('USA', {}).get('hc_bl', 'NA'):.4f}\" if bl_data.get('USA', {}).get('hc_bl') else \"  USA h: NA\")\n",
    "print(f\"  Niger h check: {bl_data.get('NER', {}).get('hc_bl', 'NA'):.4f}\" if bl_data.get('NER', {}).get('hc_bl') else \"  Niger h: NA\")\n",
    "\n",
    "# Merge Barro-Lee into master\n",
    "matched_bl = 0\n",
    "for iso in pwt_1988:\n",
    "    bl = bl_data.get(iso, {})\n",
    "    pwt_1988[iso]['yr_sch'] = bl.get('yr_sch')\n",
    "    pwt_1988[iso]['hc_bl']  = bl.get('hc_bl')\n",
    "    # Use PWT hc as fallback if Barro-Lee missing\n",
    "    if bl.get('hc_bl') is not None:\n",
    "        pwt_1988[iso]['hc'] = bl.get('hc_bl')\n",
    "        matched_bl += 1\n",
    "    else:\n",
    "        pwt_1988[iso]['hc'] = pwt_1988[iso].get('hc_pwt')  # PWT fallback\n",
    "\n",
    "print(f\"  Matched Barro-Lee to PWT: {matched_bl} countries\")\n",
    "print(f\"  Using PWT hc as fallback for: {sum(1 for v in pwt_1988.values() if v.get('hc_bl') is None and v.get('hc_pwt') is not None)} countries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "498894c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 5: Loading mining value added (1990 values)...\n",
      "  Mining data loaded for: 149 countries\n",
      "  Matched mining data: 142 countries\n",
      "  Note: Using 1990 values as proxy for 1988 (2-year deviation, documented)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: Mining Value Added (1990 proxy for 1988)\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 5: Loading mining value added (1990 values)...\")\n",
    "\n",
    "# The mining file uses country NAMES, not ISO codes.\n",
    "# We need a crosswalk for the most common name differences.\n",
    "NAME_TO_ISO = {\n",
    "    'Afghanistan': 'AFG', 'Albania': 'ALB', 'Algeria': 'DZA', 'Angola': 'AGO',\n",
    "    'Anguilla': 'AIA', 'Antigua and Barbuda': 'ATG', 'Argentina': 'ARG',\n",
    "    'Armenia': 'ARM', 'Australia': 'AUS', 'Austria': 'AUT', 'Azerbaijan': 'AZE',\n",
    "    'Bahamas': 'BHS', 'Bahrain': 'BHR', 'Bangladesh': 'BGD', 'Barbados': 'BRB',\n",
    "    'Belarus': 'BLR', 'Belgium': 'BEL', 'Belize': 'BLZ', 'Benin': 'BEN',\n",
    "    'Bhutan': 'BTN', 'Bolivia': 'BOL', 'Bosnia and Herzegovina': 'BIH',\n",
    "    'Botswana': 'BWA', 'Brazil': 'BRA', 'Brunei Darussalam': 'BRN',\n",
    "    'Bulgaria': 'BGR', 'Burkina Faso': 'BFA', 'Burundi': 'BDI',\n",
    "    'Cabo Verde': 'CPV', 'Cambodia': 'KHM', 'Cameroon': 'CMR', 'Canada': 'CAN',\n",
    "    'Central African Republic': 'CAF', 'Chad': 'TCD', 'Chile': 'CHL',\n",
    "    'China': 'CHN', 'Colombia': 'COL', 'Comoros': 'COM', 'Congo': 'COG',\n",
    "    'Costa Rica': 'CRI', 'Croatia': 'HRV', 'Cuba': 'CUB', 'Cyprus': 'CYP',\n",
    "    'Czech Republic': 'CZE', 'Czechia': 'CZE',\n",
    "    'Democratic Republic of the Congo': 'COD', 'Denmark': 'DNK',\n",
    "    'Djibouti': 'DJI', 'Dominican Republic': 'DOM', 'Ecuador': 'ECU',\n",
    "    'Egypt': 'EGY', 'El Salvador': 'SLV', 'Equatorial Guinea': 'GNQ',\n",
    "    'Eritrea': 'ERI', 'Estonia': 'EST', 'Eswatini': 'SWZ', 'Ethiopia': 'ETH',\n",
    "    'Fiji': 'FJI', 'Finland': 'FIN', 'France': 'FRA', 'Gabon': 'GAB',\n",
    "    'Gambia': 'GMB', 'Georgia': 'GEO', 'Germany': 'DEU', 'Ghana': 'GHA',\n",
    "    'Greece': 'GRC', 'Guatemala': 'GTM', 'Guinea': 'GIN',\n",
    "    'Guinea-Bissau': 'GNB', 'Guyana': 'GUY', 'Haiti': 'HTI',\n",
    "    'Honduras': 'HND', 'Hungary': 'HUN', 'Iceland': 'ISL', 'India': 'IND',\n",
    "    'Indonesia': 'IDN', 'Iran': 'IRN', 'Iran (Islamic Republic of)': 'IRN',\n",
    "    'Iraq': 'IRQ', 'Ireland': 'IRL', 'Israel': 'ISR', 'Italy': 'ITA',\n",
    "    'Jamaica': 'JAM', 'Japan': 'JPN', 'Jordan': 'JOR', 'Kazakhstan': 'KAZ',\n",
    "    'Kenya': 'KEN', 'Kuwait': 'KWT', 'Kyrgyzstan': 'KGZ', 'Lao PDR': 'LAO',\n",
    "    'Latvia': 'LVA', 'Lebanon': 'LBN', 'Lesotho': 'LSO', 'Liberia': 'LBR',\n",
    "    'Libya': 'LBY', 'Lithuania': 'LTU', 'Luxembourg': 'LUX',\n",
    "    'Madagascar': 'MDG', 'Malawi': 'MWI', 'Malaysia': 'MYS',\n",
    "    'Maldives': 'MDV', 'Mali': 'MLI', 'Malta': 'MLT', 'Mauritania': 'MRT',\n",
    "    'Mauritius': 'MUS', 'Mexico': 'MEX', 'Moldova': 'MDA', 'Mongolia': 'MNG',\n",
    "    'Morocco': 'MAR', 'Mozambique': 'MOZ', 'Myanmar': 'MMR', 'Namibia': 'NAM',\n",
    "    'Nepal': 'NPL', 'Netherlands': 'NLD', 'New Zealand': 'NZL',\n",
    "    'Nicaragua': 'NIC', 'Niger': 'NER', 'Nigeria': 'NGA', 'Norway': 'NOR',\n",
    "    'Oman': 'OMN', 'Pakistan': 'PAK', 'Panama': 'PAN',\n",
    "    'Papua New Guinea': 'PNG', 'Paraguay': 'PRY', 'Peru': 'PER',\n",
    "    'Philippines': 'PHL', 'Poland': 'POL', 'Portugal': 'PRT', 'Qatar': 'QAT',\n",
    "    'Romania': 'ROU', 'Russia': 'RUS', 'Russian Federation': 'RUS',\n",
    "    'Rwanda': 'RWA', 'Saudi Arabia': 'SAU', 'Senegal': 'SEN',\n",
    "    'Sierra Leone': 'SLE', 'Singapore': 'SGP', 'Slovakia': 'SVK',\n",
    "    'Slovenia': 'SVN', 'Somalia': 'SOM', 'South Africa': 'ZAF',\n",
    "    'South Korea': 'KOR', 'Spain': 'ESP', 'Sri Lanka': 'LKA', 'Sudan': 'SDN',\n",
    "    'Suriname': 'SUR', 'Sweden': 'SWE', 'Switzerland': 'CHE', 'Syria': 'SYR',\n",
    "    'Syrian Arab Republic': 'SYR', 'Taiwan': 'TWN', 'Tajikistan': 'TJK',\n",
    "    'Tanzania': 'TZA', 'Thailand': 'THA', 'Togo': 'TGO',\n",
    "    'Trinidad and Tobago': 'TTO', 'Tunisia': 'TUN', 'Turkey': 'TUR',\n",
    "    'Turkmenistan': 'TKM', 'Uganda': 'UGA', 'Ukraine': 'UKR',\n",
    "    'United Arab Emirates': 'ARE', 'United Kingdom': 'GBR',\n",
    "    'United Republic of Tanzania': 'TZA', 'United States': 'USA',\n",
    "    'United States of America': 'USA', 'Uruguay': 'URY', 'Uzbekistan': 'UZB',\n",
    "    'Venezuela': 'VEN', 'Venezuela (Bolivarian Republic of)': 'VEN',\n",
    "    'Viet Nam': 'VNM', 'Vietnam': 'VNM', 'Yemen': 'YEM', 'Zambia': 'ZMB',\n",
    "    'Zimbabwe': 'ZWE', 'Zaire': 'ZAR', 'Ivory Coast': 'CIV',\n",
    "    \"Côte d'Ivoire\": 'CIV', \"Cote d'Ivoire\": 'CIV',\n",
    "    'Republic of Korea': 'KOR', 'Korea, Republic of': 'KOR',\n",
    "    'Democratic People\\'s Republic of Korea': 'PRK',\n",
    "    'Swaziland': 'SWZ', 'Cape Verde': 'CPV',\n",
    "    'Bolivia (Plurinational State of)': 'BOL',\n",
    "    'Congo, Dem. Rep.': 'COD', 'Congo, Rep.': 'COG',\n",
    "}\n",
    "\n",
    "mining_data = {}\n",
    "_, mining_rows = read_xlsx_sheet(MINING_FILE, sheet_index=1)  # sheet2 = Data\n",
    "\n",
    "for row in mining_rows:\n",
    "    country_name = row.get('Country and area', '').strip()\n",
    "    if not country_name:\n",
    "        continue\n",
    "    iso = NAME_TO_ISO.get(country_name)\n",
    "    if not iso:\n",
    "        continue\n",
    "    # Use 1990 as proxy for 1988\n",
    "    val = safe_float(row.get('1990'))\n",
    "    if val is not None:\n",
    "        mining_data[iso] = val / 100  # convert % to fraction\n",
    "\n",
    "print(f\"  Mining data loaded for: {len(mining_data)} countries\")\n",
    "\n",
    "# Merge mining into master\n",
    "for iso in pwt_1988:\n",
    "    pwt_1988[iso]['mining_va'] = mining_data.get(iso)\n",
    "\n",
    "matched_mining = sum(1 for v in pwt_1988.values() if v.get('mining_va') is not None)\n",
    "print(f\"  Matched mining data: {matched_mining} countries\")\n",
    "print(f\"  Note: Using 1990 values as proxy for 1988 (2-year deviation, documented)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d176414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 6: Constructing WGI governance index...\n",
      "  WGI index computed for: 199 countries\n",
      "  USA governance check:   0.8348\n",
      "  Niger governance check: 0.3433\n",
      "  Matched WGI data: 175 countries\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: WGI Governance Index (substitute for GADP)\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 6: Constructing WGI governance index...\")\n",
    "\n",
    "# Use Rule of Law (rl), Government Effectiveness (ge), Control of Corruption (cc)\n",
    "# These are the three WGI dimensions closest to GADP components.\n",
    "# We use the Governance score (0-100) column and average the three dimensions.\n",
    "# Year: 1996 (earliest available — document as deviation from 1986-1995 GADP)\n",
    "\n",
    "WGI_SHEETS = {\n",
    "    'rl': 4,  # sheet index for rule of law\n",
    "    'ge': 2,  # sheet index for govt effectiveness\n",
    "    'cc': 5,  # sheet index for control of corruption\n",
    "}\n",
    "WGI_YEAR = '1996'\n",
    "\n",
    "wgi_scores = defaultdict(dict)\n",
    "for dim, sheet_idx in WGI_SHEETS.items():\n",
    "    _, wgi_rows = read_xlsx_sheet(WGI_FILE, sheet_index=sheet_idx)\n",
    "    for row in wgi_rows:\n",
    "        if row.get('Year') != WGI_YEAR:\n",
    "            continue\n",
    "        iso = row.get('Economy (code)', '').strip()\n",
    "        # Governance score 0-100\n",
    "        score = safe_float(row.get('Governance score (0-100)'))\n",
    "        if iso and score is not None:\n",
    "            wgi_scores[iso][dim] = score\n",
    "\n",
    "# Average across three dimensions, normalize to [0,1]\n",
    "wgi_index = {}\n",
    "for iso, dims in wgi_scores.items():\n",
    "    available = [v for v in dims.values() if v is not None]\n",
    "    if available:\n",
    "        avg = sum(available) / len(available)\n",
    "        wgi_index[iso] = avg / 100  # normalize to [0,1]\n",
    "\n",
    "print(f\"  WGI index computed for: {len(wgi_index)} countries\")\n",
    "print(f\"  USA governance check:   {wgi_index.get('USA', 'NA'):.4f}\" if wgi_index.get('USA') else \"  USA WGI: NA\")\n",
    "print(f\"  Niger governance check: {wgi_index.get('NER', 'NA'):.4f}\" if wgi_index.get('NER') else \"  Niger WGI: NA\")\n",
    "\n",
    "# Merge WGI into master\n",
    "for iso in pwt_1988:\n",
    "    pwt_1988[iso]['governance'] = wgi_index.get(iso)\n",
    "\n",
    "matched_wgi = sum(1 for v in pwt_1988.values() if v.get('governance') is not None)\n",
    "print(f\"  Matched WGI data: {matched_wgi} countries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cdc61bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 7: Computing Sachs-Warner openness fractions...\n",
      "  Openness fractions computed for: 99 countries\n",
      "  USA openness check:   1.000\n",
      "  Niger openness check: 0.000\n",
      "  Switzerland check:    1.000\n",
      "  Matched openness data: 96 countries\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: Sachs-Warner Openness (fraction of years open)\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 7: Computing Sachs-Warner openness fractions...\")\n",
    "\n",
    "# open.csv has annual binary OPEN variable (0/1) per country per year\n",
    "# We compute fraction of years open over available data (1950-1992)\n",
    "# Hall & Jones use 1950-1994, but our data ends in 1992 — documented deviation\n",
    "\n",
    "# Country name to ISO crosswalk for Sachs-Warner (uses country names)\n",
    "SW_NAME_TO_ISO = {\n",
    "    'ALGERIA': 'DZA', 'BENIN': 'BEN', 'BOTSWANA': 'BWA', 'BURKINA FASO': 'BFA',\n",
    "    'BURUNDI': 'BDI', 'CAMEROON': 'CMR', 'CAPE VERDE': 'CPV', 'CENTRAL AFRICA': 'CAF',\n",
    "    'CHAD': 'TCD', 'COMOROS': 'COM', 'CONGO': 'COG', 'DJIBOUTI': 'DJI',\n",
    "    'EGYPT': 'EGY', 'ETHIOPIA': 'ETH', 'GABON': 'GAB', 'GAMBIA': 'GMB',\n",
    "    'GHANA': 'GHA', 'GUINEA': 'GIN', 'GUINEA-BISSAU': 'GNB',\n",
    "    'IVORY COAST': 'CIV', 'KENYA': 'KEN', 'LESOTHO': 'LSO', 'LIBERIA': 'LBR',\n",
    "    'MADAGASCAR': 'MDG', 'MALAWI': 'MWI', 'MALI': 'MLI', 'MAURITANIA': 'MRT',\n",
    "    'MAURITIUS': 'MUS', 'MOROCCO': 'MAR', 'MOZAMBIQUE': 'MOZ', 'NAMIBIA': 'NAM',\n",
    "    'NIGER': 'NER', 'NIGERIA': 'NGA', 'RWANDA': 'RWA', 'SENEGAL': 'SEN',\n",
    "    'SEYCHELLES': 'SYC', 'SIERRA LEONE': 'SLE', 'SOMALIA': 'SOM',\n",
    "    'SOUTH AFRICA': 'ZAF', 'SUDAN': 'SDN', 'SWAZILAND': 'SWZ',\n",
    "    'TANZANIA': 'TZA', 'TOGO': 'TGO', 'TUNISIA': 'TUN', 'UGANDA': 'UGA',\n",
    "    'ZAIRE': 'ZAR', 'ZAMBIA': 'ZMB', 'ZIMBABWE': 'ZWE',\n",
    "    'BAHAMAS': 'BHS', 'BARBADOS': 'BRB', 'BELIZE': 'BLZ', 'CANADA': 'CAN',\n",
    "    'COSTA RICA': 'CRI', 'DOMINICA': 'DMA', 'DOMINICAN REPUBLIC': 'DOM',\n",
    "    'EL SALVADOR': 'SLV', 'GRENADA': 'GRD', 'GUATEMALA': 'GTM',\n",
    "    'HAITI': 'HTI', 'HONDURAS': 'HND', 'JAMAICA': 'JAM', 'MEXICO': 'MEX',\n",
    "    'NICARAGUA': 'NIC', 'PANAMA': 'PAN', 'PUERTO RICO': 'PRI',\n",
    "    'TRINIDAD AND TOBAGO': 'TTO', 'TRINIDAD & TOBAGO': 'TTO',\n",
    "    'UNITED STATES': 'USA', 'U.S.A.': 'USA', 'U.S.S.R.': 'SUN',\n",
    "    'BRAZIL': 'BRA', 'CHILE': 'CHL', 'COLOMBIA': 'COL', 'ECUADOR': 'ECU',\n",
    "    'GUYANA': 'GUY', 'PARAGUAY': 'PRY', 'PERU': 'PER', 'SURINAME': 'SUR',\n",
    "    'URUGUAY': 'URY', 'VENEZUELA': 'VEN', 'BAHRAIN': 'BHR',\n",
    "    'BANGLADESH': 'BGD', 'BHUTAN': 'BTN', 'CHINA': 'CHN', 'HONG KONG': 'HKG',\n",
    "    'INDIA': 'IND', 'INDONESIA': 'IDN', 'IRAN': 'IRN', 'IRAQ': 'IRQ',\n",
    "    'ISRAEL': 'ISR', 'JAPAN': 'JPN', 'JORDAN': 'JOR', 'KOREA': 'KOR',\n",
    "    'KUWAIT': 'KWT', 'LAOS': 'LAO', 'MALAYSIA': 'MYS', 'MONGOLIA': 'MNG',\n",
    "    'MYANMAR': 'MMR', 'NEPAL': 'NPL', 'OMAN': 'OMN', 'PAKISTAN': 'PAK',\n",
    "    'PHILIPPINES': 'PHL', 'QATAR': 'QAT', 'SAUDI ARABIA': 'SAU',\n",
    "    'SINGAPORE': 'SGP', 'SRI LANKA': 'LKA', 'SYRIA': 'SYR', 'TAIWAN': 'TWN',\n",
    "    'THAILAND': 'THA', 'UNITED ARAB EMIRATES': 'ARE', 'YEMEN': 'YEM',\n",
    "    'AUSTRIA': 'AUT', 'BELGIUM': 'BEL', 'BULGARIA': 'BGR', 'CYPRUS': 'CYP',\n",
    "    'CZECHOSLOVAKIA': 'CZE', 'DENMARK': 'DNK', 'FINLAND': 'FIN',\n",
    "    'FRANCE': 'FRA', 'GERMANY': 'DEU', 'WEST GERMANY': 'DEU',\n",
    "    'GREECE': 'GRC', 'HUNGARY': 'HUN', 'ICELAND': 'ISL', 'IRELAND': 'IRL',\n",
    "    'ITALY': 'ITA', 'LUXEMBOURG': 'LUX', 'MALTA': 'MLT',\n",
    "    'NETHERLANDS': 'NLD', 'NORWAY': 'NOR', 'POLAND': 'POL',\n",
    "    'PORTUGAL': 'PRT', 'ROMANIA': 'ROU', 'SPAIN': 'ESP', 'SWEDEN': 'SWE',\n",
    "    'SWITZERLAND': 'CHE', 'TURKEY': 'TUR', 'UNITED KINGDOM': 'GBR',\n",
    "    'SOVIET UNION': 'SUN', 'YUGOSLAVIA': 'YUG', 'AUSTRALIA': 'AUS',\n",
    "    'FIJI': 'FJI', 'NEW ZEALAND': 'NZL', 'PAPUA NEW GUINEA': 'PNG',\n",
    "}\n",
    "\n",
    "open_years = defaultdict(lambda: {'open': 0, 'total': 0})\n",
    "with open(OPEN_FILE, 'r', encoding='latin1') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        country = row.get('COUNTRY', '').strip().upper()\n",
    "        iso = SW_NAME_TO_ISO.get(country)\n",
    "        if not iso:\n",
    "            continue\n",
    "        open_val = row.get('OPEN')\n",
    "        if open_val is None:\n",
    "            continue\n",
    "        open_val = str(open_val).strip()\n",
    "        if open_val in ('0.00', '1.00', '0', '1'):\n",
    "            open_years[iso]['total'] += 1\n",
    "            if open_val in ('1.00', '1'):\n",
    "                open_years[iso]['open'] += 1\n",
    "\n",
    "openness_fracs = {}\n",
    "for iso, counts in open_years.items():\n",
    "    if counts['total'] > 0:\n",
    "        openness_fracs[iso] = counts['open'] / counts['total']\n",
    "\n",
    "print(f\"  Openness fractions computed for: {len(openness_fracs)} countries\")\n",
    "print(f\"  USA openness check:   {openness_fracs.get('USA', 'NA'):.3f}\" if 'USA' in openness_fracs else \"  USA: NA\")\n",
    "print(f\"  Niger openness check: {openness_fracs.get('NER', 'NA'):.3f}\" if 'NER' in openness_fracs else \"  Niger: NA\")\n",
    "print(f\"  Switzerland check:    {openness_fracs.get('CHE', 'NA'):.3f}\" if 'CHE' in openness_fracs else \"  CHE: NA\")\n",
    "\n",
    "# Merge openness into master\n",
    "for iso in pwt_1988:\n",
    "    pwt_1988[iso]['openness'] = openness_fracs.get(iso)\n",
    "\n",
    "matched_open = sum(1 for v in pwt_1988.values() if v.get('openness') is not None)\n",
    "print(f\"  Matched openness data: {matched_open} countries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1559f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 8: Merging instruments...\n",
      "  Distance from equator matched: 168\n",
      "  FR trade matched:              139\n",
      "  Language data matched:         166\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 8: Instruments — Distance from Equator, FR Trade, Language\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 8: Merging instruments...\")\n",
    "\n",
    "# Distance from equator\n",
    "geo_data = {}\n",
    "with open(GEO_FILE, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        iso = row.get('iso3', '').strip()\n",
    "        dist = safe_float(row.get('distancefromeq'))\n",
    "        if iso:\n",
    "            geo_data[iso] = dist\n",
    "\n",
    "# Frankel-Romer predicted trade share\n",
    "fr_data = {}\n",
    "with open(FR_FILE, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        iso = row.get('iso3', '').strip()\n",
    "        fr_val = safe_float(row.get('fr_constructed_trade_share'))\n",
    "        if iso:\n",
    "            fr_data[iso] = fr_val\n",
    "\n",
    "# Language fractions\n",
    "lang_data = {}\n",
    "with open(LANG_FILE, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        iso = row.get('iso3', '').strip()\n",
    "        eng = safe_float(row.get('english_frac'))\n",
    "        we  = safe_float(row.get('we_lang_frac'))\n",
    "        if iso:\n",
    "            lang_data[iso] = {'english_frac': eng, 'we_lang_frac': we}\n",
    "\n",
    "# Merge all instruments\n",
    "for iso in pwt_1988:\n",
    "    pwt_1988[iso]['distancefromeq'] = geo_data.get(iso)\n",
    "    pwt_1988[iso]['fr_trade']       = fr_data.get(iso)\n",
    "    pwt_1988[iso]['english_frac']   = lang_data.get(iso, {}).get('english_frac')\n",
    "    pwt_1988[iso]['we_lang_frac']   = lang_data.get(iso, {}).get('we_lang_frac')\n",
    "\n",
    "print(f\"  Distance from equator matched: {sum(1 for v in pwt_1988.values() if v.get('distancefromeq') is not None)}\")\n",
    "print(f\"  FR trade matched:              {sum(1 for v in pwt_1988.values() if v.get('fr_trade') is not None)}\")\n",
    "print(f\"  Language data matched:         {sum(1 for v in pwt_1988.values() if v.get('english_frac') is not None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac460e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 9: Constructing social infrastructure index...\n",
      "  Social infrastructure index computed for: 96 countries\n",
      "  USA S = 0.9174\n",
      "  CHE S = 0.9471\n",
      "  NER S = 0.1716\n",
      "  ZAR S = NA\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 9: Construct Social Infrastructure Index\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 9: Constructing social infrastructure index...\")\n",
    "\n",
    "# S = (governance + openness) / 2\n",
    "# Both already on [0,1] scale (governance normalized from 0-100, openness is a fraction)\n",
    "# This mirrors Hall & Jones: S = (GADP + Sachs-Warner) / 2\n",
    "\n",
    "for iso, d in pwt_1988.items():\n",
    "    gov = d.get('governance')\n",
    "    opn = d.get('openness')\n",
    "    if gov is not None and opn is not None:\n",
    "        d['social_infra'] = (gov + opn) / 2\n",
    "    elif gov is not None:\n",
    "        d['social_infra'] = None  # require both components\n",
    "    elif opn is not None:\n",
    "        d['social_infra'] = None\n",
    "    else:\n",
    "        d['social_infra'] = None\n",
    "\n",
    "n_si = sum(1 for v in pwt_1988.values() if v.get('social_infra') is not None)\n",
    "print(f\"  Social infrastructure index computed for: {n_si} countries\")\n",
    "\n",
    "# Quick check: Switzerland and US should be near top, Niger near bottom\n",
    "for check_iso in ['USA', 'CHE', 'NER', 'ZAR']:\n",
    "    si = pwt_1988.get(check_iso, {}).get('social_infra')\n",
    "    print(f\"  {check_iso} S = {si:.4f}\" if si is not None else f\"  {check_iso} S = NA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ccea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 10: Final assembly and quality check...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 10: Final Assembly and Quality Check\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 10: Final assembly and quality check...\")\n",
    "\n",
    "# Define the complete set of variables in the output\n",
    "OUTPUT_VARS = [\n",
    "    'iso3', 'country',\n",
    "    # Core variables\n",
    "    'yl',           # output per worker (Y/L) — main dependent variable\n",
    "    'rgdpo',        # real GDP (mil 2017 USD PPP)\n",
    "    'emp',          # employment (millions)\n",
    "    'pop',          # population (millions)\n",
    "    # Production function components\n",
    "    'K',            # capital stock\n",
    "    'ky_ratio',     # capital-output ratio K/Y\n",
    "    'hc',           # human capital index (Mincerian, from Barro-Lee; PWT fallback)\n",
    "    'hc_bl',        # human capital from Barro-Lee specifically\n",
    "    'hc_pwt',       # human capital from PWT (for comparison)\n",
    "    'yr_sch',       # average years of schooling (Barro-Lee 1985)\n",
    "    # Natural resource correction\n",
    "    'mining_va',    # mining value added as fraction of GDP\n",
    "    # Social infrastructure\n",
    "    'governance',   # WGI composite (rl+ge+cc avg, normalized 0-1)\n",
    "    'openness',     # Sachs-Warner fraction of years open\n",
    "    'social_infra', # S = (governance + openness) / 2\n",
    "    # Instruments\n",
    "    'distancefromeq',  # |latitude| / 90\n",
    "    'fr_trade',        # Frankel-Romer constructed trade share\n",
    "    'english_frac',    # fraction speaking English natively\n",
    "    'we_lang_frac',    # fraction speaking Western European language natively\n",
    "    # Auxiliary\n",
    "    'delta',           # depreciation rate\n",
    "    'labsh',           # labor share (for checking alpha assumption)\n",
    "    'csh_i',           # investment share of GDP\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad823cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Complete cases (yl + K/Y + hc + S all present): 93\n",
      "  Total countries in dataset: 183\n",
      "  Countries with Y/L data: 149\n",
      "\n",
      "  Missing data summary:\n",
      "    yl                  :  34 missing out of 183\n",
      "    ky_ratio            :  26 missing out of 183\n",
      "    hc                  :  40 missing out of 183\n",
      "    yr_sch              :  45 missing out of 183\n",
      "    mining_va           :  41 missing out of 183\n",
      "    governance          :   8 missing out of 183\n",
      "    openness            :  87 missing out of 183\n",
      "    social_infra        :  87 missing out of 183\n",
      "    distancefromeq      :  15 missing out of 183\n",
      "    fr_trade            :  44 missing out of 183\n"
     ]
    }
   ],
   "source": [
    "# Count complete cases (all core variables present)\n",
    "core_vars = ['yl', 'ky_ratio', 'hc', 'social_infra']\n",
    "complete = {\n",
    "    iso: d for iso, d in pwt_1988.items()\n",
    "    if all(d.get(v) is not None for v in core_vars)\n",
    "}\n",
    "print(f\"  Complete cases (yl + K/Y + hc + S all present): {len(complete)}\")\n",
    "print(f\"  Total countries in dataset: {len(pwt_1988)}\")\n",
    "\n",
    "# Countries with Y/L only (for partial replication)\n",
    "has_yl = {iso: d for iso, d in pwt_1988.items() if d.get('yl') is not None}\n",
    "print(f\"  Countries with Y/L data: {len(has_yl)}\")\n",
    "\n",
    "# Missing data summary\n",
    "print(\"\\n  Missing data summary:\")\n",
    "for var in ['yl', 'ky_ratio', 'hc', 'yr_sch', 'mining_va', 'governance', 'openness', 'social_infra', 'distancefromeq', 'fr_trade']:\n",
    "    n_missing = sum(1 for d in pwt_1988.values() if d.get(var) is None)\n",
    "    print(f\"    {var:<20}: {n_missing:>3} missing out of {len(pwt_1988)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda4a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 11: Saving master dataset to C:\\Users\\Adams\\OneDrive\\DE & E Research\\outputs\\merged.csv...\n",
      "  Saved 183 countries to C:\\Users\\Adams\\OneDrive\\DE & E Research\\outputs\\merged.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 11: Save Output\n",
    "# =============================================================================\n",
    "print(f\"\\n>>> STEP 11: Saving master dataset to {OUTPUT_FILE}...\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=OUTPUT_VARS, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    for iso in sorted(pwt_1988.keys()):\n",
    "        row = {var: pwt_1988[iso].get(var, '') for var in OUTPUT_VARS}\n",
    "        # Round floats to 6 decimal places\n",
    "        for var in OUTPUT_VARS:\n",
    "            val = row[var]\n",
    "            if isinstance(val, float):\n",
    "                row[var] = round(val, 6)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"  Saved {len(pwt_1988)} countries to {OUTPUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c396eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STEP 12: Verification against Hall & Jones Table I...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 12: Verification Table — Reproduce key rows from Hall & Jones Table I\n",
    "# =============================================================================\n",
    "print(\"\\n>>> STEP 12: Verification against Hall & Jones Table I...\")\n",
    "\n",
    "# Expected approximate values from paper (scaled to US = 1.0)\n",
    "# Note: exact values will differ because we use updated data and WGI instead of GADP\n",
    "verify_countries = {\n",
    "    'USA': {'rank_yl': 1},\n",
    "    'CAN': {},\n",
    "    'GBR': {},\n",
    "    'FRA': {},\n",
    "    'DEU': {},\n",
    "    'JPN': {},\n",
    "    'BRA': {},\n",
    "    'CHN': {},\n",
    "    'IND': {},\n",
    "    'KEN': {},\n",
    "    'NGA': {},\n",
    "    'NER': {},\n",
    "    'ZAR': {},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "728d7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ISO     Y/L (rel USA)  K/Y (rel USA)  h (rel USA)        S\n",
      "  ------------------------------------------------------------\n",
      "  USA             1.000          1.000        1.000    0.917\n",
      "  CAN             0.874          0.940        0.855    0.907\n",
      "  GBR             0.684          0.962        0.775       NA\n",
      "  JPN             0.631          1.152        0.822    0.738\n",
      "  FRA             0.803          1.134        0.656    0.793\n",
      "  DEU             0.629          1.221        0.721       NA\n",
      "  BRA             0.204          0.715        0.477    0.278\n",
      "  CHN             0.059          0.663        0.545    0.224\n",
      "  IND             0.042          0.628        0.406    0.250\n",
      "  KEN             0.077          0.377        0.446    0.275\n",
      "  NGA             0.043          7.099        0.359    0.154\n",
      "  NER             0.038          0.882        0.317    0.172\n",
      "\n",
      "  Note: Values differ from original paper because:\n",
      "  (1) PWT 10.01 uses 2017 prices, original used PWT 5.6 with 1985 prices\n",
      "  (2) WGI (1996) used instead of GADP (1986-1995)\n",
      "  (3) Capital stock constructed from updated investment data\n",
      "  These deviations should be documented in the replication report.\n",
      "\n",
      ">>> PIPELINE COMPLETE. Master dataset saved to: C:\\Users\\Adams\\OneDrive\\DE & E Research\\outputs\\merged.csv\n",
      "    Next step: Run Hall & Jones analysis (levels accounting + IV regression)\n"
     ]
    }
   ],
   "source": [
    "# Get USA values for normalization\n",
    "usa = pwt_1988.get('USA', {})\n",
    "usa_yl    = usa.get('yl', 1)\n",
    "usa_ky    = usa.get('ky_ratio', 1)\n",
    "usa_hc    = usa.get('hc', 1)\n",
    "\n",
    "print(f\"\\n  {'ISO':<6} {'Y/L (rel USA)':>14} {'K/Y (rel USA)':>14} {'h (rel USA)':>12} {'S':>8}\")\n",
    "print(f\"  {'-'*60}\")\n",
    "\n",
    "for iso in ['USA', 'CAN', 'GBR', 'JPN', 'FRA', 'DEU', 'BRA', 'CHN', 'IND', 'KEN', 'NGA', 'NER']:\n",
    "    d = pwt_1988.get(iso, {})\n",
    "    yl  = d.get('yl')\n",
    "    ky  = d.get('ky_ratio')\n",
    "    hc  = d.get('hc')\n",
    "    si  = d.get('social_infra')\n",
    "\n",
    "    rel_yl = f\"{yl/usa_yl:.3f}\"   if (yl and usa_yl) else 'NA'\n",
    "    rel_ky = f\"{ky/usa_ky:.3f}\"   if (ky and usa_ky) else 'NA'\n",
    "    rel_hc = f\"{hc/usa_hc:.3f}\"   if (hc and usa_hc) else 'NA'\n",
    "    si_str = f\"{si:.3f}\"          if si is not None  else 'NA'\n",
    "\n",
    "    print(f\"  {iso:<6} {rel_yl:>14} {rel_ky:>14} {rel_hc:>12} {si_str:>8}\")\n",
    "\n",
    "print(\"\\n  Note: Values differ from original paper because:\")\n",
    "print(\"  (1) PWT 10.01 uses 2017 prices, original used PWT 5.6 with 1985 prices\")\n",
    "print(\"  (2) WGI (1996) used instead of GADP (1986-1995)\")\n",
    "print(\"  (3) Capital stock constructed from updated investment data\")\n",
    "print(\"  These deviations should be documented in the replication report.\")\n",
    "\n",
    "print(\"\\n>>> PIPELINE COMPLETE. Master dataset saved to:\", OUTPUT_FILE)\n",
    "print(\"    Next step: Run Hall & Jones analysis (levels accounting + IV regression)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
